{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a411ff-2688-49da-a546-ac219d991c66",
   "metadata": {},
   "source": [
    "修改service/.env文件\n",
    "设置OPENAI_API_KEY为app4gpt后台获取的Key\n",
    "设置OPENAI_API_BASE_URL为https://api.app4gpt.com\n",
    "由于网络延迟，建议把TIMEOUT_MS设置为180000或者更高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45094a0-6a61-4c77-b095-3b0f7843de39",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "# %env OPENAI_API_KEY=sk-JDyfBDx2med8q8JBxlHY5tXKsHaz5691CPhsEsr4oSGZAAAA\n",
    "# %env OPENAI_API_KEY=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\n",
    "%env OPENAI_API_KEY=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\n",
    "# %env OPENAI_API_BASE=https://api.app4gpt.com/v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ce412-b7bc-4ebf-bcff-46d90b660a7a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "安装 llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2777156-24b1-43d4-b0b7-0d6b8814fbfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.6.32-py3-none-any.whl (532 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.3/532.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
      "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
      "Collecting langchain>=0.0.154 (from llama-index)\n",
      "  Downloading langchain-0.0.214-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting sqlalchemy>=2.0.15 (from llama-index)\n",
      "  Downloading SQLAlchemy-2.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from llama-index) (1.23.3)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting openai>=0.26.4 (from llama-index)\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from llama-index) (1.5.0)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/lib/python3.8/site-packages (from llama-index) (1.26.11)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect==0.8.0 (from llama-index)\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting typing-extensions==4.5.0 (from llama-index)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tiktoken (from llama-index)\n",
      "  Downloading tiktoken-0.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect==0.8.0->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (4.0.2)\n",
      "Collecting langchainplus-sdk>=0.0.17 (from langchain>=0.0.154->llama-index)\n",
      "  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain>=0.0.154->llama-index)\n",
      "  Downloading numexpr-2.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.7/381.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.154->llama-index)\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2,>=1 (from langchain>=0.0.154->llama-index)\n",
      "  Downloading pydantic-1.10.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.8/site-packages (from langchain>=0.0.154->llama-index) (2.28.1)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json->llama-index)\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json->llama-index)\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from openai>=0.26.4->llama-index) (4.64.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy>=2.0.15->llama-index) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->llama-index) (2022.4)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->llama-index)\n",
      "  Downloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2->langchain>=0.0.154->llama-index) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2->langchain>=0.0.154->llama-index) (2023.5.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (3.0.9)\n",
      "Installing collected packages: typing-extensions, tenacity, regex, numexpr, mypy-extensions, fsspec, typing-inspect, tiktoken, sqlalchemy, pydantic, marshmallow, openapi-schema-pydantic, openai, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain, llama-index\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: numexpr\n",
      "    Found existing installation: numexpr 2.8.3\n",
      "    Uninstalling numexpr-2.8.3:\n",
      "      Successfully uninstalled numexpr-2.8.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.8.2\n",
      "    Uninstalling fsspec-2022.8.2:\n",
      "      Successfully uninstalled fsspec-2022.8.2\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.41\n",
      "    Uninstalling SQLAlchemy-1.4.41:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.41\n",
      "Successfully installed dataclasses-json-0.5.8 fsspec-2023.6.0 langchain-0.0.214 langchainplus-sdk-0.0.17 llama-index-0.6.32 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 numexpr-2.8.4 openai-0.27.8 openapi-schema-pydantic-1.2.4 pydantic-1.10.9 regex-2023.6.3 sqlalchemy-2.0.17 tenacity-8.2.2 tiktoken-0.4.0 typing-extensions-4.5.0 typing-inspect-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a394eb04-bca6-40b9-9d62-391570ed4f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e96c9fa-6370-4ed4-818f-be4db7be2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdec1390-78b0-4eb9-8533-9b5e1024968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.proxy=\"http://v2ray:8118\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413d844-6cff-470e-a417-2ff263d9e27b",
   "metadata": {},
   "source": [
    "# Build and Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353d6f74-dd2c-4a3c-9df8-9d959e47291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c8eb5c9-c5b9-48b9-a026-c80661186dbf",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a5382-365b-46e5-a67a-8ae69a93d51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b74e561-2e5d-485a-a318-b1f42f721c70",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3e08095-14a0-4cd0-976e-a10a7db61dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(text=\"supra is my nickname and supra's garage is my blog web site\", doc_id='eace872b-7dbf-4d7b-bd34-27d24d71d876', embedding=None, doc_hash='235012dd57f1b9e01ed7b4713c86beab2a980582a4537a832de41d48a4e2e5d6', extra_info=None)\n"
     ]
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7d64f9e-66dd-422d-89bb-25aa8149ff23",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9d04dad-faf2-40f7-9883-4fa5e6853d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbfd7aac-f66f-4cea-96b9-0ab5ec2aec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The author grew up writing essays, learning Italian, exploring Florence, painting people, working with computers, studying at RISD, living in a rent-controlled apartment, building an online store builder, editing code, publishing essays online, writing essays, working on spam filters, cooking for groups, buying a building, and attending parties.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4548801-4e6e-496d-8fb7-8d64c0515f29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangChain是一个用于开发由语言模型驱动的应用程序的框架。它主要拥有2个功能：搜索并给出回答、总结PDF文档、基于某个Youtube视频进行问答等等。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"LangChain是什么?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73b8bf1f-395f-43a5-9f9f-6b6548fca965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Supra's Garage is a blog web site.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what's is supra's garage?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2b5e269-ea7c-4d18-afd1-ee2ecbe501fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_append = SimpleDirectoryReader('data_append').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5de7f6ee-66f2-494a-967f-4b9b940d6107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfce46b8-2658-4f22-9073-cc34b3496e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(text=\"the url host for supra's garage is supra.tw\", doc_id='fe8e4029-9c55-4314-9289-08770f3f34f4', embedding=None, doc_hash='98bba8360c4a20f5d5c658b520d9ae07f714804ad78b74a63ab37a4eb76fd405', extra_info=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_append[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26cdf217-d4dd-4c25-a09f-1fea3aa256af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in documents_append:\n",
    "    index.update_ref_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db140784-ef14-43f1-9cb5-489f15d87c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ad850ba-4275-4b20-85d9-5a5f287d057e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The blog web site address for supra's garage is: supra.tw\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"show my blog web site address\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9979d1b1-dcb6-4bbb-a9c0-b1f0a7b83fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34a32718-16ff-4bb7-bf15-000ccaa44d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5637e980-bc13-492a-9efb-d03d1853dfec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85590d6d-9617-44b7-a6ce-0c57da2afe05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f23e044-8170-43c8-a4fb-1dbef031b027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/embeddings\n",
      "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/embeddings\n",
      "DEBUG:openai:api_version=None data='{\"input\": [\"give me the index page url for supra\\'s garage blog web site\"], \"model\": \"text-embedding-ada-002\", \"encoding_format\": \"base64\"}' message='Post details'\n",
      "api_version=None data='{\"input\": [\"give me the index page url for supra\\'s garage blog web site\"], \"model\": \"text-embedding-ada-002\", \"encoding_format\": \"base64\"}' message='Post details'\n",
      "DEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443\n",
      "Starting new HTTPS connection (1): api.openai.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/embeddings HTTP/1.1\" 200 None\n",
      "https://api.openai.com:443 \"POST /v1/embeddings HTTP/1.1\" 200 None\n",
      "DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=71 request_id=c722625878e54930469a5d2509f3364e response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=71 request_id=c722625878e54930469a5d2509f3364e response_code=200\n",
      "DEBUG:llama_index.indices.utils:> Top 2 nodes:\n",
      "> [Node 77221153-55fc-4372-bf7b-6e738233cac5] [Similarity score:             0.899706] supra is my nickname and supra's garage is my blog web site...\n",
      "> [Node 1572c060-904c-48b0-92d1-ab8a5faa05d3] [Similarity score:             0.89443] the url host for supra's garage is supra.tw...\n",
      "> Top 2 nodes:\n",
      "> [Node 77221153-55fc-4372-bf7b-6e738233cac5] [Similarity score:             0.899706] supra is my nickname and supra's garage is my blog web site...\n",
      "> [Node 1572c060-904c-48b0-92d1-ab8a5faa05d3] [Similarity score:             0.89443] the url host for supra's garage is supra.tw...\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 13 tokens\n",
      "> [retrieve] Total embedding token usage: 13 tokens\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions\n",
      "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions\n",
      "DEBUG:openai:api_version=None data='{\"prompt\": [\"Context information is below.\\\\n---------------------\\\\nsupra is my nickname and supra\\'s garage is my blog web site\\\\n\\\\nthe url host for supra\\'s garage is supra.tw\\\\n---------------------\\\\nGiven the context information and not prior knowledge, answer the question: give me the index page url for supra\\'s garage blog web site\\\\n\"], \"model\": \"text-davinci-003\", \"temperature\": 0.0, \"max_tokens\": 4030, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"n\": 1, \"logit_bias\": {}}' message='Post details'\n",
      "api_version=None data='{\"prompt\": [\"Context information is below.\\\\n---------------------\\\\nsupra is my nickname and supra\\'s garage is my blog web site\\\\n\\\\nthe url host for supra\\'s garage is supra.tw\\\\n---------------------\\\\nGiven the context information and not prior knowledge, answer the question: give me the index page url for supra\\'s garage blog web site\\\\n\"], \"model\": \"text-davinci-003\", \"temperature\": 0.0, \"max_tokens\": 4030, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"n\": 1, \"logit_bias\": {}}' message='Post details'\n",
      "DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/completions HTTP/1.1\" 200 None\n",
      "https://api.openai.com:443 \"POST /v1/completions HTTP/1.1\" 200 None\n",
      "DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=944 request_id=fbcc05f633bc7e222a345c32d579c819 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=944 request_id=fbcc05f633bc7e222a345c32d579c819 response_code=200\n",
      "DEBUG:llama_index.llm_predictor.base:\n",
      "The index page URL for supra's garage blog web site is: http://supra.tw/index.html\n",
      "\n",
      "The index page URL for supra's garage blog web site is: http://supra.tw/index.html\n",
      "DEBUG:llama_index.indices.response.base_builder:> Initial prompt template: Context information is below.\n",
      "---------------------\n",
      "supra is my nickname and supra's garage is my blog web site\n",
      "\n",
      "the url host for supra's garage is supra.tw\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the question: give me the index page url for supra's garage blog web site\n",
      "\n",
      "> Initial prompt template: Context information is below.\n",
      "---------------------\n",
      "supra is my nickname and supra's garage is my blog web site\n",
      "\n",
      "the url host for supra's garage is supra.tw\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the question: give me the index page url for supra's garage blog web site\n",
      "\n",
      "DEBUG:llama_index.indices.response.base_builder:> Initial response: \n",
      "The index page URL for supra's garage blog web site is: http://supra.tw/index.html\n",
      "> Initial response: \n",
      "The index page URL for supra's garage blog web site is: http://supra.tw/index.html\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 91 tokens\n",
      "> [get_response] Total LLM token usage: 91 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "The index page URL for supra's garage blog web site is: http://supra.tw/index.html\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"give me the index page url for supra's garage blog web site\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a65fd44-b259-44ea-9adb-897e6f17d72b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/docstore.json\n",
      "open file: /home/jovyan/work/storage/docstore.json\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/index_store.json\n",
      "open file: /home/jovyan/work/storage/index_store.json\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/vector_store.json\n",
      "open file: /home/jovyan/work/storage/vector_store.json\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/graph_store.json\n",
      "open file: /home/jovyan/work/storage/graph_store.json\n"
     ]
    }
   ],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "171aa2df-25b2-4d1e-8159-1bfba9b28aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25407027-1810-426c-8214-a08bf1dd07f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/docstore.json\n",
      "open file: /home/jovyan/work/storage/docstore.json\n",
      "DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
      "Loading llama_index.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/index_store.json\n",
      "open file: /home/jovyan/work/storage/index_store.json\n",
      "DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./storage/vector_store.json.\n",
      "Loading llama_index.vector_stores.simple from ./storage/vector_store.json.\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/vector_store.json\n",
      "open file: /home/jovyan/work/storage/vector_store.json\n",
      "DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./storage/graph_store.json.\n",
      "Loading llama_index.graph_stores.simple from ./storage/graph_store.json.\n",
      "DEBUG:fsspec.local:open file: /home/jovyan/work/storage/graph_store.json\n",
      "open file: /home/jovyan/work/storage/graph_store.json\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "687ecb3c-8233-433f-8f1e-0e4d1dfad2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801c151-e5f1-4074-9acc-e9532fbbd795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09dec1fd1d0840208fb6ed7792552ab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "182aecc8d8304e11838c62436b2a76e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6d066cf37b64403196ba33f2998d0a0a",
       "style": "IPY_MODEL_09dec1fd1d0840208fb6ed7792552ab9",
       "value": " 1.04M/? [00:00&lt;00:00, 2.22MB/s]"
      }
     },
     "191b371f84ae4365b3054f2e2e3e1d80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1b005217ccc94310a2cc0a369e8d5ab4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4daf156c8c8b4e5bb16b0b8d28eb70e3",
       "max": 1,
       "style": "IPY_MODEL_76839bb18e194e4b8210c2f384598815",
       "value": 1
      }
     },
     "1f5112bab85d4612b2ea3eb4ed41a64d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_36e60945180c4ba5bf7c3fc090423814",
       "style": "IPY_MODEL_2f0b23fc568a48838735a39b0dbc8e3c",
       "value": " 665/665 [00:00&lt;00:00, 12.4kB/s]"
      }
     },
     "20a4c107562e4740965b8a639fee9bea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "20f1d7c719364e08a9acd6808cfa3a6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "225a09faa1be4475892024ef22c7328e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2be9d55fb4684dd79c322e9145e8df28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_76954a5a326c44c0abc6f87addfb919f",
       "max": 1,
       "style": "IPY_MODEL_33e489a3b4cc4fd6bc19c77903f6434c",
       "value": 1
      }
     },
     "2f0b23fc568a48838735a39b0dbc8e3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "309fdbb256cf4618b87136d69d5843a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33e489a3b4cc4fd6bc19c77903f6434c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "36e60945180c4ba5bf7c3fc090423814": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b879cc22ec8428591b967a1123059b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3da5778026a240b2a42854ba5e5adb76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_20a4c107562e4740965b8a639fee9bea",
       "max": 1,
       "style": "IPY_MODEL_3b879cc22ec8428591b967a1123059b0",
       "value": 1
      }
     },
     "42a4945a12454799b3712bb3eef3a55c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43b8008a851b44f292f5bb645aa0c891": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "470e4d03e8cb4e27affc482eae588bcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ebae11ecde394695a15dfe9d695646dc",
       "style": "IPY_MODEL_225a09faa1be4475892024ef22c7328e",
       "value": " 456k/? [00:00&lt;00:00, 812kB/s]"
      }
     },
     "47d3e4898c964594927168ef9dab727c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4daf156c8c8b4e5bb16b0b8d28eb70e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "512c8d880d6445be9bf9472ae98037b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_aaeb73dfe5f04f188587ca6c1ec8c810",
        "IPY_MODEL_3da5778026a240b2a42854ba5e5adb76",
        "IPY_MODEL_182aecc8d8304e11838c62436b2a76e2"
       ],
       "layout": "IPY_MODEL_ce0477f98b3f45b79d5e262290ce8b83"
      }
     },
     "52484effdbae4242b48bb11efc5dce3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_47d3e4898c964594927168ef9dab727c",
       "style": "IPY_MODEL_c34bac6bfabd45eebb83bb9f257b3c55",
       "value": " 1.36M/? [00:00&lt;00:00, 2.56MB/s]"
      }
     },
     "5ecd2f3437bb4d08bf221220a0d0842c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6149cd0c156e4be09e1a6518b51f3457": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_43b8008a851b44f292f5bb645aa0c891",
       "style": "IPY_MODEL_6cccdea0e12e4f9b919d171c9bb053b2",
       "value": "Downloading (…)olve/main/merges.txt: "
      }
     },
     "6ca6a1533c38479e9b1d9146dfe3fb7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cc1eee785ab2458d93651030d40364e1",
       "max": 665,
       "style": "IPY_MODEL_b4f94bbfec134b4c9f680994bc8ee1b9",
       "value": 665
      }
     },
     "6cccdea0e12e4f9b919d171c9bb053b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d066cf37b64403196ba33f2998d0a0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "72ab8cd3c1e041c3967a057fbf04c83f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_904ddabd52a14334aec219734e96d39b",
        "IPY_MODEL_2be9d55fb4684dd79c322e9145e8df28",
        "IPY_MODEL_52484effdbae4242b48bb11efc5dce3c"
       ],
       "layout": "IPY_MODEL_fc1bf3c2929143b0975e0b5bc70c1491"
      }
     },
     "76839bb18e194e4b8210c2f384598815": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "76954a5a326c44c0abc6f87addfb919f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "82d2ce1965f042668399ba61790266d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6149cd0c156e4be09e1a6518b51f3457",
        "IPY_MODEL_1b005217ccc94310a2cc0a369e8d5ab4",
        "IPY_MODEL_470e4d03e8cb4e27affc482eae588bcf"
       ],
       "layout": "IPY_MODEL_191b371f84ae4365b3054f2e2e3e1d80"
      }
     },
     "8c3bc357948c4502b0678ce64e7ac42b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "904ddabd52a14334aec219734e96d39b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5ecd2f3437bb4d08bf221220a0d0842c",
       "style": "IPY_MODEL_fd03a64e9fa5432a858a929bca4dd51b",
       "value": "Downloading (…)/main/tokenizer.json: "
      }
     },
     "aaeb73dfe5f04f188587ca6c1ec8c810": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42a4945a12454799b3712bb3eef3a55c",
       "style": "IPY_MODEL_20f1d7c719364e08a9acd6808cfa3a6a",
       "value": "Downloading (…)olve/main/vocab.json: "
      }
     },
     "af5f9bbf4e824b3f8ee8a23c9a9fc6e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b4f94bbfec134b4c9f680994bc8ee1b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c34bac6bfabd45eebb83bb9f257b3c55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc1eee785ab2458d93651030d40364e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce0477f98b3f45b79d5e262290ce8b83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ebae11ecde394695a15dfe9d695646dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f75f1faf5d4d46979d2fe5a51eb7867a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_309fdbb256cf4618b87136d69d5843a8",
       "style": "IPY_MODEL_af5f9bbf4e824b3f8ee8a23c9a9fc6e4",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "fb333901ec8f4329b7ed87d964320b29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f75f1faf5d4d46979d2fe5a51eb7867a",
        "IPY_MODEL_6ca6a1533c38479e9b1d9146dfe3fb7d",
        "IPY_MODEL_1f5112bab85d4612b2ea3eb4ed41a64d"
       ],
       "layout": "IPY_MODEL_8c3bc357948c4502b0678ce64e7ac42b"
      }
     },
     "fc1bf3c2929143b0975e0b5bc70c1491": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fd03a64e9fa5432a858a929bca4dd51b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
